{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3c6003f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is **New Delhi**.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "model = ChatGoogleGenerativeAI(model='gemini-2.5-flash',temperature=0.1)\n",
    "\n",
    "result = model.invoke('What is the capital of India')\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c56b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_FILE_PATH = 'data/yelp.csv' \n",
    "SAMPLE_SIZE = 200 \n",
    "\n",
    "def load_and_sample_data(file_path: str, sample_size: int) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path)\n",
    "    required_cols = ['stars', 'text']\n",
    "\n",
    "    df_filtered = df[required_cols].copy()\n",
    "    df_filtered.rename(columns={'stars': 'actual_stars'}, inplace=True)\n",
    "    \n",
    "    # Sample and clean\n",
    "    df_sample = df_filtered.sample(n=min(sample_size, len(df_filtered)), random_state=42).reset_index(drop=True)\n",
    "    df_sample.dropna(subset=['text'], inplace=True)\n",
    "    \n",
    "    return df_sample\n",
    "\n",
    "# Load and prepare the data - This DataFrame will be used for all subsequent steps\n",
    "reviews_df = load_and_sample_data(DATA_FILE_PATH, SAMPLE_SIZE)\n",
    "# reviews_df now holds the 200 rows of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40b02616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_stars</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>We got here around midnight last Friday... the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Brought a friend from Louisiana here.  She say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Every friday, my dad and I eat here. We order ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>My husband and I were really, really disappoin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Love this place!  Was in phoenix 3 weeks for w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual_stars                                               text\n",
       "0             4  We got here around midnight last Friday... the...\n",
       "1             5  Brought a friend from Louisiana here.  She say...\n",
       "2             3  Every friday, my dad and I eat here. We order ...\n",
       "3             1  My husband and I were really, really disappoin...\n",
       "4             5  Love this place!  Was in phoenix 3 weeks for w..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d9220e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_v1 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are a sentiment analysis assistant.\n",
    "\n",
    "Your task:\n",
    "- Read the following review.\n",
    "- Predict what star rating (1 to 5) the customer most likely gave.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY an integer 1, 2, 3, 4, or 5.\n",
    "- 1 = very negative, 3 = mixed/average, 5 = very positive.\n",
    "- Base your answer ONLY on the review text.\n",
    "- Respond ONLY in valid JSON with this exact format (no backticks, no markdown):\n",
    "\n",
    "{{\n",
    "  \"predicted_stars\": <integer between 1 and 5>,\n",
    "  \"explanation\": \"<brief reasoning in one or two sentences>\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY the JSON object, nothing else.\n",
    "\"\"\",\n",
    "input_variables=['review_text']\n",
    ")\n",
    "template_v1.name = \"template_v1\"\n",
    "\n",
    "\n",
    "template_v2 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an assistant that maps Yelp reviews to star ratings (1–5) and returns strict JSON\n",
    "\n",
    "Use this rubric:\n",
    "- 1 star: Very negative, serious issues, strong dissatisfaction.\n",
    "- 2 stars: Mostly negative, some minor positives but overall unhappy.\n",
    "- 3 stars: Mixed/average, clear positives and negatives.\n",
    "- 4 stars: Mostly positive, small issues but generally satisfied.\n",
    "- 5 stars: Very positive, highly satisfied, would strongly recommend.\n",
    "\n",
    "Instructions:\n",
    "- Use ONLY integers 1, 2, 3, 4, or 5 for the rating.\n",
    "- Provide a short, one-sentence explanation.\n",
    "- Return ONLY valid JSON — no markdown, no extra text.\n",
    "\n",
    "Expected JSON format:\n",
    "{{\n",
    "  \"predicted_stars\": <integer between 1 and 5>,\n",
    "  \"explanation\": \"<brief one-sentence justification>\"\n",
    "}}\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY the JSON object.\n",
    "\"\"\",\n",
    "    input_variables=['review_text']\n",
    ")\n",
    "\n",
    "template_v2.name = \"template_v2\"\n",
    "\n",
    "template_v3 = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "You are an assistant that maps Yelp reviews to star ratings (1–5) and returns strict JSON.\n",
    "\n",
    "IMPORTANT: You may internally reason step-by-step to arrive at the best rating (i.e., use chain-of-thought internally). \n",
    "HOWEVER, do NOT output any chain-of-thought, reasoning steps, or internal deliberation. \n",
    "Output ONLY the final JSON object in the exact schema below — nothing else.\n",
    "\n",
    "Follow this exact JSON format:\n",
    "{{\n",
    "  \"predicted_stars\": <integer between 1 and 5>,\n",
    "  \"explanation\": \"<brief explanation>\"\n",
    "}}\n",
    "\n",
    "Examples (input -> exact JSON output):\n",
    "\n",
    "Example 1\n",
    "Review:\n",
    "\\\"\\\"\\\"U can go there n check the car out. If u wanna buy 1 there? That's wrong move! ... They ripped my girlfriend off by lying how bad my car is now.\\\"\\\"\\\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 1,\n",
    "  \"explanation\": \"Strongly negative: accuses the business of ripping customers off and warns others not to go.\"\n",
    "}}\n",
    "\n",
    "Example 2\n",
    "Review:\n",
    "\\\"\\\"\\\"Was it worth the 21$ for a salad and small pizza? Absolutely not! Bad service. ... I left hungry, mad and unsatisfied. Won't go back unless I'm desperate.\\\"\\\"\\\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 2,\n",
    "  \"explanation\": \"Mostly negative: criticizes value and service, expresses dissatisfaction and intent not to return.\"\n",
    "}}\n",
    "\n",
    "Example 3\n",
    "Review:\n",
    "\\\"\\\"\\\"We went here on a Saturday afternoon and this place was incredibly empty. ... My entree was the Tilapia salad, and I was a bit disappointed. It wasn't bad enough to say I wouldn't go back, but I won't be anxiously awaiting my next trip.\\\"\\\"\\\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 3,\n",
    "  \"explanation\": \"Mixed/average: mentions both positive aspects and clear disappointments; overall lukewarm.\"\n",
    "}}\n",
    "\n",
    "Example 4\n",
    "Review:\n",
    "\\\"\\\"\\\"Love the gyro plate. Rice is so good and I also dig their candy selection :)\\\"\\\"\\\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 4,\n",
    "  \"explanation\": \"Mostly positive: praises food with minor issues implied.\"\n",
    "}}\n",
    "\n",
    "Example 5\n",
    "Review:\n",
    "\\\"\\\"\\\"My wife took me here on my birthday for breakfast and it was excellent. ... Do yourself a favor and get their Bloody Mary. It was phenomenal and simply the best I've ever had.\\\"\\\"\\\"\n",
    "Output:\n",
    "{{\n",
    "  \"predicted_stars\": 5,\n",
    "  \"explanation\": \"Very positive: enthusiastic praise for food, service, and overall experience.\"\n",
    "}}\n",
    "\n",
    "Now classify the following review using the SAME JSON format.\n",
    "\n",
    "Review:\n",
    "\\\"\\\"\\\"{review_text}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY the JSON object — no markdown, no text outside the JSON, and absolutely no chain-of-thought or reasoning steps.\n",
    "\"\"\",\n",
    "    input_variables=['review_text']\n",
    ")\n",
    "\n",
    "template_v3.name = \"template_v3\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7107a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cfea6418",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_json_parse(json_string: str):\n",
    "    try:\n",
    "        data = json.loads(json_string)\n",
    "        return data, True\n",
    "    except:\n",
    "        return None, False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f2a7e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_prompt(\n",
    "    template: PromptTemplate,\n",
    "    df: pd.DataFrame,\n",
    "    model: ChatGoogleGenerativeAI\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    total = len(df)\n",
    "    template_name = getattr(template, \"name\", \"unnamed_template\")\n",
    "    print(f\"\\n--- Running Evaluation for {template_name} ({total} samples) ---\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        review_text = row['text']\n",
    "        actual_stars = row['actual_stars']\n",
    "\n",
    "        prompt = template.format(review_text=review_text)\n",
    "        pred_star = None\n",
    "        json_valid = False\n",
    "\n",
    "        try:\n",
    "            # synchronous invocation\n",
    "            response = model.invoke(prompt)\n",
    "\n",
    "            # access response content robustly (raw output only)\n",
    "            if hasattr(response, \"content\"):\n",
    "                raw_text = response.content\n",
    "            elif isinstance(response, dict) and \"content\" in response:\n",
    "                raw_text = response[\"content\"]\n",
    "            else:\n",
    "                raw_text = str(response)\n",
    "\n",
    "            # STRICT parse (no cleaning)\n",
    "            parsed_data, parsed_ok = strict_json_parse(raw_text)\n",
    "            json_valid = bool(parsed_ok)\n",
    "\n",
    "            # Only accept predicted_stars if it's an int in [1,5]\n",
    "            if json_valid and isinstance(parsed_data, dict):\n",
    "                potential = parsed_data.get(\"predicted_stars\")\n",
    "                if isinstance(potential, int) and 1 <= potential <= 5:\n",
    "                    pred_star = int(potential)\n",
    "                else:\n",
    "                    pred_star = None\n",
    "            else:\n",
    "                pred_star = None\n",
    "\n",
    "        except Exception:\n",
    "            # Keep defaults: pred_star None and json_valid False\n",
    "            pass\n",
    "\n",
    "        results.append({\n",
    "            'actual_stars': actual_stars,\n",
    "            'predicted_stars': pred_star,\n",
    "            'json_valid': json_valid,\n",
    "            'is_accurate': (pred_star == actual_stars)\n",
    "        })\n",
    "\n",
    "        # progress log every 20 rows (and final row)\n",
    "        if (idx + 1) % 20 == 0 or (idx + 1) == total:\n",
    "            print(f\"Processed {idx+1}/{total} reviews... (template={template_name})\")\n",
    "\n",
    "    print(f\"✔ Completed evaluation for {template_name}\\n\")\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fb46e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_metrics(results_df: pd.DataFrame) -> dict:\n",
    "   \n",
    "    valid_predictions_df = results_df.dropna(subset=['predicted_stars']).copy()\n",
    "    \n",
    "    # Ensure columns are numeric for calculation\n",
    "    if not valid_predictions_df.empty:\n",
    "        valid_predictions_df['predicted_stars'] = valid_predictions_df['predicted_stars'].astype(int)\n",
    "        valid_predictions_df['actual_stars'] = valid_predictions_df['actual_stars'].astype(int)\n",
    "\n",
    "    # --- Metric Calculation ---\n",
    "\n",
    "    # 2. Accuracy: Proportion of valid predictions that exactly match the actual rating.\n",
    "    accuracy = valid_predictions_df['is_accurate'].mean() if not valid_predictions_df.empty else 0.0\n",
    "    \n",
    "    # 3. Mean Absolute Error (MAE): Average absolute difference between predicted and actual stars.\n",
    "    if not valid_predictions_df.empty:\n",
    "        # Calculate |Predicted - Actual| for all valid rows\n",
    "        mae_series = (valid_predictions_df['predicted_stars'] - valid_predictions_df['actual_stars']).abs()\n",
    "        mae = mae_series.mean()\n",
    "    else:\n",
    "        mae = 0.0\n",
    "\n",
    "    # 4. JSON Validity Rate: Proportion of all samples that produced a parseable JSON response.\n",
    "    # This uses the entire results_df, including samples with None predictions.\n",
    "    json_valid_rate = results_df['json_valid'].mean()\n",
    "    \n",
    "    return {\n",
    "        'Total Samples': len(results_df),\n",
    "        'Accuracy': f\"{accuracy:.4f}\",\n",
    "        'Mean Absolute Error (MAE)': f\"{mae:.4f}\",\n",
    "        'JSON Validity Rate': f\"{json_valid_rate:.4f}\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ea1255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Evaluation for template_v1 (200 samples) ---\n",
      "Processed 20/200 reviews... (template=template_v1)\n",
      "Processed 40/200 reviews... (template=template_v1)\n",
      "Processed 60/200 reviews... (template=template_v1)\n",
      "Processed 80/200 reviews... (template=template_v1)\n",
      "Processed 100/200 reviews... (template=template_v1)\n",
      "Processed 120/200 reviews... (template=template_v1)\n",
      "Processed 140/200 reviews... (template=template_v1)\n",
      "Processed 160/200 reviews... (template=template_v1)\n",
      "Processed 180/200 reviews... (template=template_v1)\n",
      "Processed 200/200 reviews... (template=template_v1)\n",
      "✔ Completed evaluation for template_v1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_v1 = evaluate_prompt(\n",
    "    template=template_v1,\n",
    "    df=reviews_df, \n",
    "    model=model\n",
    ")\n",
    "metrics_v1 = aggregate_metrics(results_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cffcbcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Evaluation for template_v2 (200 samples) ---\n",
      "Processed 20/200 reviews... (template=template_v2)\n",
      "Processed 40/200 reviews... (template=template_v2)\n",
      "Processed 60/200 reviews... (template=template_v2)\n",
      "Processed 80/200 reviews... (template=template_v2)\n",
      "Processed 100/200 reviews... (template=template_v2)\n",
      "Processed 120/200 reviews... (template=template_v2)\n",
      "Processed 140/200 reviews... (template=template_v2)\n",
      "Processed 160/200 reviews... (template=template_v2)\n",
      "Processed 180/200 reviews... (template=template_v2)\n",
      "Processed 200/200 reviews... (template=template_v2)\n",
      "✔ Completed evaluation for template_v2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_v2 = evaluate_prompt(\n",
    "    template=template_v2,\n",
    "    df=reviews_df, \n",
    "    model=model\n",
    ")\n",
    "metrics_v2 = aggregate_metrics(results_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff611910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Running Evaluation for template_v3 (200 samples) ---\n",
      "Processed 20/200 reviews... (template=template_v3)\n",
      "Processed 40/200 reviews... (template=template_v3)\n",
      "Processed 60/200 reviews... (template=template_v3)\n",
      "Processed 80/200 reviews... (template=template_v3)\n",
      "Processed 100/200 reviews... (template=template_v3)\n",
      "Processed 120/200 reviews... (template=template_v3)\n",
      "Processed 140/200 reviews... (template=template_v3)\n",
      "Processed 160/200 reviews... (template=template_v3)\n",
      "Processed 180/200 reviews... (template=template_v3)\n",
      "Processed 200/200 reviews... (template=template_v3)\n",
      "✔ Completed evaluation for template_v3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_v3 = evaluate_prompt(\n",
    "    template=template_v3,\n",
    "    df=reviews_df, \n",
    "    model=model\n",
    ")\n",
    "metrics_v3 = aggregate_metrics(results_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61f922b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strategy</th>\n",
       "      <th>Total Samples</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Mean Absolute Error (MAE)</th>\n",
       "      <th>JSON Validity Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>template_v1</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>0.5231</td>\n",
       "      <td>0.9750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>template_v2</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5865</td>\n",
       "      <td>0.4423</td>\n",
       "      <td>0.5200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>template_v3</td>\n",
       "      <td>200</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>0.9600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      strategy  Total Samples Accuracy Mean Absolute Error (MAE)  \\\n",
       "0  template_v1            200   0.5333                    0.5231   \n",
       "1  template_v2            200   0.5865                    0.4423   \n",
       "2  template_v3            200   0.5729                    0.4792   \n",
       "\n",
       "  JSON Validity Rate  \n",
       "0             0.9750  \n",
       "1             0.5200  \n",
       "2             0.9600  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df = pd.DataFrame([\n",
    "    {\"strategy\": template_v1.name, **metrics_v1},\n",
    "    {\"strategy\": template_v2.name, **metrics_v2},\n",
    "    {\"strategy\": template_v3.name, **metrics_v3},\n",
    "])\n",
    "comparison_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
